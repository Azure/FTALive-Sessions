# Split of Data
This module focusses on certain database scenarios which should help you narrow down your options for storing data. Often neglected these are few important concepts one must consider before creating pipelines

## Transactional Data
This is the day to day data that gets generated through transactions

## Historical Data
This is data you dont generate every day

## Analytical Data

A data lake is a centralized repository that ingests and stores large volumes of data in its original form.

Delta Lake is an open-source storage layer that brings ACID (atomicity, consistency, isolation, and durability) transactions to Apache Spark and big data workloads.

Large-scale data warehousing solutions combine conventional data warehousing used to support business intelligence (BI) with techniques used for so-called "big data" analytics. A conventional data warehousing solution typically involves copying data from transactional data stores into a relational database with a schema that's optimized for querying and building multidimensional models.
 
## Additional Information
- [Important data engineering concepts](https://learn.microsoft.com/en-us/training/modules/introduction-to-data-engineering-azure/4-common-patterns-azure-data-engineering)