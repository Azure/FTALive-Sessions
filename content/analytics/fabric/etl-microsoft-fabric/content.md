## Step-by-Step Tutorial: Building ETLs with Microsoft Fabric

### Introduction:
In this comprehensive guide, we'll walk you through the process of creating Extract, Transform, Load (ETL) pipelines using Microsoft Fabric. Follow these steps to leverage the power of Fabric and efficiently manage your data workflows.

![basic architeture](https://github.com/Azure/FTALive-Sessions/assets/105279899/6fd72cbd-0ecc-4323-a93e-92889862fe26)

we would like to extract data from ADLS, transform it using Fabric Notebooks and then load it into Fabric Lakehouse.

### Perquisites:
* Basic knowledge in ADLS, ETL's and PySpark.
* workspace in Microsoft Fabric and storage account in ADLS Gen 2.

## Challenge: Implement ETL's using Synapse Notebooks in Microsoft Fabric
 We would like to preform ETL on our raw data, converting our CSV file into parquets 
and save it in ADLS using the ADLS shortcut in lakehouse. 
		

## Solution: How does Synapse notebooks component simplify the ETL process of a our data in Microsoft Fabric?
Synapse notebooks is an important component of Microsoft Fabric, it allow us to use dynamic ETL's using Pyspark/scala etc. 
		

### Demo : Let's explore how we can execute ETL in Microsoft Fabric today.
		

### FAQ
1. [How can I configure notebooks in Microsoft Fabirc?](https://learn.microsoft.com/en-us/fabric/data-engineering/how-to-use-notebook)
1. [How to start with Microsoft Fabirc](https://learn.microsoft.com/en-us/fabric/)
1. Is it a replacement to Azure Data Factory data flows?
1. When will it go GA?

