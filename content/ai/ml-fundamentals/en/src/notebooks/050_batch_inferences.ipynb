{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run parallel batch inference at scale"
   ],
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "dataset = ws.datasets[\"diabetes-tabular\"]\n",
    "compute_target = ws.compute_targets[\"cpu-cluster\"]"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1631727007382
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Create a big dataset (452.608 rows) named pending-diabetes\n",
    "df = dataset.drop_columns(\"target\").to_pandas_dataframe()\n",
    "\n",
    "print(f\"Original DataFrame's size {df.memory_usage(deep=True).sum()}\")\n",
    "\n",
    "for x in range(10):\n",
    "    df = df.append(df)\n",
    "print(f\"Expanded DataFrame's size {df.memory_usage(deep=True).sum()}\")\n",
    "df.insert(0, \"id\", range(1, len(df) + 1))\n",
    "\n",
    "dstore = ws.get_default_datastore()\n",
    "pending_records_ds = Dataset.Tabular.register_pandas_dataframe(\n",
    "    dataframe=df,\n",
    "    target=(dstore, \"/samples/pending-diabetes\"),\n",
    "    name=\"pending-diabetes\",\n",
    "    description=\"Pending diabetes records to be processed\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1631727014037
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
    "\n",
    "ds_pipeline_param = PipelineParameter(name=\"dataset\", default_value=pending_records_ds)\n",
    "step01_input_dataset = DatasetConsumptionConfig(\"input_dataset\", ds_pipeline_param)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1631727014097
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig\n",
    "\n",
    "# Configure parallel step\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=\"050_scripts\",\n",
    "    entry_script=\"tabular_batch.py\",\n",
    "    mini_batch_size=\"400Kb\",\n",
    "    error_threshold=-1,\n",
    "    output_action=\"append_row\",\n",
    "    append_row_file_name=\"diabetes_outputs.txt\",\n",
    "    environment=ws.environments[\"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\"],\n",
    "    compute_target=compute_target,\n",
    "    node_count=2,\n",
    "    process_count_per_node=10,\n",
    "    run_invocation_timeout=600,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1631727014148
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "# Configure where to output inferences\n",
    "datastore = ws.get_default_datastore()\n",
    "step_output = OutputFileDatasetConfig(\n",
    "    name=\"results_store\", destination=(datastore, \"/inferences/diabetes/\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1631727014194
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.pipeline.steps import ParallelRunStep\n",
    "\n",
    "parallel_step = ParallelRunStep(\n",
    "    name=\"parallel-inference\",\n",
    "    inputs=[step01_input_dataset],\n",
    "    output=step_output,\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    allow_reuse=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1631727014246
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallel_step])\n",
    "\n",
    "pipeline_run = Experiment(ws, \"parallel-inference-run\").submit(pipeline)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1631727018117
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3-azureml",
   "language": "python",
   "display_name": "Python 3.8 - AzureML"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
