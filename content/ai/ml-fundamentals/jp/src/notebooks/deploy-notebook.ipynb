{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning による機械学習プロセス - デプロイ編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アジェンダ\n",
    "### A. 学習編\n",
    "- ワークスペース (Workspace) への接続\n",
    "- データセット (Datasets) の登録\n",
    "- 環境 (Environments) の登録\n",
    "- コンピューティングクラスター (Compute Clusters) の作成\n",
    "- モデル学習の実行と実験 (Runs & Experiments)\n",
    "- モデル登録 (Models)\n",
    "\n",
    "### **B. デプロイ編 (本ノートブック)**\n",
    "- ワークスペース (Workspace) への接続\n",
    "- 推論環境の作成 (Endpoints)\n",
    "- エンドポイントの利用 (Endpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前設定\n",
    "- 本ノートブックは Azure Machine Learning の Compute Instances を利用することを想定しています。\n",
    "- 開発環境は JupyterLab, VSCode, Integrated Notebook など Compute Instances で稼働するものであれば自由に選択いただけます。\n",
    "- カーネルは `python38-azureml (Python 3.8 AzureML)` を選択ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペース (Workspace) への接続\n",
    "クライアント環境の Python 環境にインストールした Azure ML Python SDK を用いて Azure Machine Learning Workspace に接続します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649081976581
    }
   },
   "outputs": [],
   "source": [
    "# Compute Instances を利用する場合\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649081976640
    }
   },
   "outputs": [],
   "source": [
    "# # その他の任意のクライアント環境を利用する場合\n",
    "# ws = Workspace.get(\n",
    "#     name='name',\n",
    "#     subscription_id='subscription_id',\n",
    "#     resource_group='resource_group',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論環境の作成 (Endpoints)\n",
    "下記の情報を利用してモデルをデプロイし、推論環境を作成します。\n",
    "- 登録済みのモデル (Modelss)\n",
    "- 推論環境で稼働する環境 (Environments)\n",
    "- 推論スクリプト : _score.py_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649081976707
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Model\n",
    "from azureml.core.webservice import LocalWebservice, AciWebservice\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 登録済みのモデル (Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649081977548
    }
   },
   "outputs": [],
   "source": [
    "model = Model(ws, \"lgb-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 推論環境で稼働する環境 (Environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649081977662
    }
   },
   "outputs": [],
   "source": [
    "env = Environment.get(ws, \"lightgbm-python-env\")\n",
    "# env.inferencing_stack_version = 'latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649081977755
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 推論スクリプト _score.py_\n",
    "`script` フォルダに予め作成済みです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "def data_preprocess(df, categorical_cols, float_cols):\n",
    "    df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "    df[float_cols] = df[float_cols].astype('float')\n",
    "    return df\n",
    "\n",
    "\n",
    "def init():\n",
    "    global bst\n",
    "    model_root = os.getenv(\"AZUREML_MODEL_DIR\")\n",
    "    # The name of the folder in which to look for LightGBM model files\n",
    "    lgbm_model_folder = \"model\"\n",
    "    bst = lgb.Booster(\n",
    "        model_file=os.path.join(model_root, lgbm_model_folder, \"model.lgb\")\n",
    "    )\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    categorical_cols = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "    float_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "    columns = bst.feature_name()\n",
    "    data = np.array(json.loads(raw_data)[\"data\"])\n",
    "    test_df_original = pd.DataFrame(data=data, columns=columns)\n",
    "    test_df = data_preprocess(test_df_original, categorical_cols, float_cols)\n",
    "    # Make prediction\n",
    "    out = bst.predict(test_df)\n",
    "    return out.tolist()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "コードや環境 (Environments) の情報を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649081977843
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(\n",
    "    entry_script=\"score.py\", source_directory=\"script\", environment=env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "最初にローカル環境にデプロイをします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082310789
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "localconfig = LocalWebservice.deploy_configuration(port=8890)\n",
    "local_service_name = \"ftalive-localmodel\"\n",
    "local_service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=local_service_name,\n",
    "    models=[model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=localconfig,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "テストデータを入力して予測値を算出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082511636
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# テストデータ\n",
    "data = {\n",
    "    \"data\": [\n",
    "        [\n",
    "            2,\n",
    "            \"Kvillner, Mr. Johan Henrik Johannesson\",\n",
    "            \"male\",\n",
    "            31,\n",
    "            0,\n",
    "            0,\n",
    "            \"C.A. 18723\",\n",
    "            10.5,\n",
    "            \"\",\n",
    "            \"S\",\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_sample = json.dumps(data)\n",
    "test_sample = str.encode(test_sample, encoding=\"utf8\")\n",
    "\n",
    "prediction = local_service.run(input_data=test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に Azure Container Instance へデプロイをします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082516974
    }
   },
   "outputs": [],
   "source": [
    "aciconfig = AciWebservice.deploy_configuration(auth_enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Container Instance にモデルをデプロイします。<br>\n",
    "なお、`service_name` は文字から始まる 3 以上 32 小文字・数字・記号 (ダッシュのみ)で記載ください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082517621
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "aciconfig.validate_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082524737
    }
   },
   "outputs": [],
   "source": [
    "service_name = \"ftalive-lgb-aci\"\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=service_name,\n",
    "    models=[model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=aciconfig,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649084385605
    }
   },
   "outputs": [],
   "source": [
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649084385651
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning Studio にて正常に登録されていることを確認します。<br>\n",
    "<img src=\"../../docs/images/azureml-deployment1.png\" width=500><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エンドポイントの利用 (Endpoints)\n",
    "推論環境にテストデータをインプットして、デプロイした機械学習モデルから予測値を算出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082311275
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "# テストデータ\n",
    "data = {\n",
    "    \"data\": [\n",
    "        [\n",
    "            2,\n",
    "            \"Kvillner, Mr. Johan Henrik Johannesson\",\n",
    "            \"male\",\n",
    "            31,\n",
    "            0,\n",
    "            0,\n",
    "            \"C.A. 18723\",\n",
    "            10.5,\n",
    "            \"\",\n",
    "            \"S\",\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "body = str.encode(json.dumps(data), encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082311281
    }
   },
   "outputs": [],
   "source": [
    "url = service.scoring_uri\n",
    "key, _ = service.get_keys()\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "req = urllib.request.Request(url, body, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649082311289
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", \"ignore\")))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
